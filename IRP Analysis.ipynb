{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b104998",
   "metadata": {},
   "source": [
    "# IRP Analysis #\n",
    "Using existing BirdNET Analyzer model to identify birds from recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29541386",
   "metadata": {},
   "source": [
    "### 1. Identify birds, run algorithm on audio files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithm on folders for unburned/burned sclerophyll sites (days 10/31 - 11/4)\n",
    "for recording_day in os.listdir('./audio/'):\n",
    "    !python3 analyze.py --i ./audio/{recording_day} --o ./results/{recording_day} --lat -25.35 --lon 153.5 --week 43 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb34734",
   "metadata": {},
   "source": [
    "### 2. Clean, convert algorithm output (.txt/each recording) to single .csv ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "778189ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD: addData\n",
    "# Params: filename (single recording .txt), output (.csv)\n",
    "# Returns: NA\n",
    "# ---\n",
    "# Identifies every birds (their highest confidence) from \n",
    "# algorithm .txt output and adds to .csv\n",
    "\n",
    "def addData(filename, output):\n",
    "    result_f = open(filename, \"r\")\n",
    "    lines = result_f.readlines()\n",
    "\n",
    "    # Consolidate info from text file\n",
    "    birds = {}\n",
    "    for line in lines[1:]:\n",
    "        bird_end = -8\n",
    "        bird_start = line[:bird_end].rfind('\\t') + 1\n",
    "        \n",
    "        bird = line[bird_start:bird_end]  \n",
    "        conf = float(line[-7:-1])\n",
    "\n",
    "        if bird not in birds:\n",
    "            birds[bird] = conf\n",
    "        else:\n",
    "            birds[bird] = max(conf, birds[bird])\n",
    "    \n",
    "    # Add to .csv   \n",
    "    date_raw = filename[25:33]\n",
    "    time_raw = filename[34:40]\n",
    "    \n",
    "    date = date_raw[:4] + '-' + date_raw[4:6] + '-' + date_raw[6:]\n",
    "    time = time_raw[:2] + ':' + time_raw[2:4]\n",
    "    \n",
    "    for bird, conf in birds.items():\n",
    "        output.writerow([date, time, bird, conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run addData on folders for unburned/burned sclerophyll sites (days 10/31 - 11/4)\n",
    "data_f = open('IRP_data.csv', 'w')\n",
    "writer = csv.writer(data_f)\n",
    "\n",
    "for recording_dir in os.listdir('./results/'):\n",
    "    for recording_txt in os.listdir('./results/' + recording_dir):\n",
    "         filename = './results/' + recording_dir + '/' + recording_txt\n",
    "         addData(filename, writer)\n",
    "        \n",
    "data_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb3aca",
   "metadata": {},
   "source": [
    "### Repeating Steps 1-2 on Dilli data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e551eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Species list contains 138 species\n",
      "Found 18 files to analyze\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T060000+1000_Rec.wav\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T080000+1000_Rec.wav\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T100000+1000_Rec.wav\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T120000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T100000+1000_Rec.wav in 60.11 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T110000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T120000+1000_Rec.wav in 60.53 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T130000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T080000+1000_Rec.wav in 60.84 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T090000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T060000+1000_Rec.wav in 61.23 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T070000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T110000+1000_Rec.wav in 46.83 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T140000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T090000+1000_Rec.wav in 48.20 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T160000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T130000+1000_Rec.wav in 49.60 seconds\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T070000+1000_Rec.wav in 49.04 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T180000+1000_Rec.wav\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T200000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T140000+1000_Rec.wav in 53.92 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T150000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T160000+1000_Rec.wav in 52.40 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T170000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T180000+1000_Rec.wav in 54.14 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T190000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T200000+1000_Rec.wav in 54.67 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T210000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T170000+1000_Rec.wav in 49.13 seconds\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T150000+1000_Rec.wav in 49.74 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T220000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T210000+1000_Rec.wav in 49.36 seconds\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T190000+1000_Rec.wav in 50.60 seconds\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T220000+1000_Rec.wav in 37.68 seconds\n",
      "Analyzing ./extra_recordings/20221029_STUDY/20221029T230000+1000_Rec.wav\n",
      "Finished ./extra_recordings/20221029_STUDY/20221029T230000+1000_Rec.wav in 31.21 seconds\n"
     ]
    }
   ],
   "source": [
    "!python3 analyze.py --i ./extra_recordings/20221029_STUDY --o ./results/20221029_STUDY --lat -25.35 --lon 153.5 --week 43 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2c9c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = open('dilli_data.csv', 'w')\n",
    "writer = csv.writer(data_f)\n",
    "\n",
    "for filename in os.listdir('./results/20221029_STUDY'):\n",
    "    addData('./results/20221029_STUDY/' + filename, writer)\n",
    "        \n",
    "data_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
